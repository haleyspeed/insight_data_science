{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achievements now have completion dates for each user and a tally of how many achievements each player completed for every month from Jan 2010 to may 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up timeseries dataframe\n",
    "Arrange the data so that rows = date, columns = achievements per month, index = player_realm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-210de4e46057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcustom_funcs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfile_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_time_stats.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'unicode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import config as cn\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import custom_funcs as cf\n",
    "\n",
    "file_in = os.path.join(os.path.join(cn.clean_dir, 'final_time_stats.csv'))\n",
    "player_cols = ['player', 'realm', 'last_login', 'time_since_login', 'status','gear_score', '2020-05']\n",
    "dfa_dates = cf.get_dates()\n",
    "keep_cols = player_cols + dfa_dates[-74:]\n",
    "keep_cols.append('engagement')\n",
    "df = pd.read_csv(file_in, dtype = 'unicode')\n",
    "extra_cols = [col for col in df.columns.values if 'unnamed' in col.lower() or  col not in keep_cols]\n",
    "df = df.drop(extra_cols, axis = 1)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "df_original = df.copy()\n",
    "display(HTML(df.head().to_html()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 242957 entries, 0 to 363669\n",
      "Data columns (total 81 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   player            242956 non-null  object \n",
      " 1   realm             242957 non-null  object \n",
      " 2   gear_score        242940 non-null  float64\n",
      " 3   last_login        242940 non-null  object \n",
      " 4   time_since_login  242957 non-null  object \n",
      " 5   2015-01           144838 non-null  float64\n",
      " 6   2016-01           144838 non-null  float64\n",
      " 7   2017-01           144838 non-null  float64\n",
      " 8   2018-01           144838 non-null  float64\n",
      " 9   2019-01           144838 non-null  float64\n",
      " 10  2020-01           144838 non-null  float64\n",
      " 11  2015-02           144838 non-null  float64\n",
      " 12  2016-02           144838 non-null  float64\n",
      " 13  2017-02           144838 non-null  float64\n",
      " 14  2018-02           144838 non-null  float64\n",
      " 15  2019-02           144838 non-null  float64\n",
      " 16  2020-02           144838 non-null  float64\n",
      " 17  2015-03           144838 non-null  float64\n",
      " 18  2016-03           144838 non-null  float64\n",
      " 19  2017-03           144838 non-null  float64\n",
      " 20  2018-03           144838 non-null  float64\n",
      " 21  2019-03           144838 non-null  float64\n",
      " 22  2020-03           144838 non-null  float64\n",
      " 23  2014-04           144838 non-null  float64\n",
      " 24  2015-04           144838 non-null  float64\n",
      " 25  2016-04           144838 non-null  float64\n",
      " 26  2017-04           144838 non-null  float64\n",
      " 27  2018-04           144838 non-null  float64\n",
      " 28  2019-04           144838 non-null  float64\n",
      " 29  2020-04           144838 non-null  float64\n",
      " 30  2014-05           144838 non-null  float64\n",
      " 31  2015-05           144838 non-null  float64\n",
      " 32  2016-05           144838 non-null  float64\n",
      " 33  2017-05           144838 non-null  float64\n",
      " 34  2018-05           144838 non-null  float64\n",
      " 35  2019-05           144838 non-null  float64\n",
      " 36  2020-05           144838 non-null  float64\n",
      " 37  2014-06           144838 non-null  float64\n",
      " 38  2015-06           144838 non-null  float64\n",
      " 39  2016-06           144838 non-null  float64\n",
      " 40  2017-06           144838 non-null  float64\n",
      " 41  2018-06           144838 non-null  float64\n",
      " 42  2019-06           144838 non-null  float64\n",
      " 43  2014-07           144838 non-null  float64\n",
      " 44  2015-07           144838 non-null  float64\n",
      " 45  2016-07           144838 non-null  float64\n",
      " 46  2017-07           144838 non-null  float64\n",
      " 47  2018-07           144838 non-null  float64\n",
      " 48  2019-07           144838 non-null  float64\n",
      " 49  2014-08           144838 non-null  float64\n",
      " 50  2015-08           144838 non-null  float64\n",
      " 51  2016-08           144838 non-null  float64\n",
      " 52  2017-08           144838 non-null  float64\n",
      " 53  2018-08           144838 non-null  float64\n",
      " 54  2019-08           144838 non-null  float64\n",
      " 55  2014-09           144838 non-null  float64\n",
      " 56  2015-09           144838 non-null  float64\n",
      " 57  2016-09           144838 non-null  float64\n",
      " 58  2017-09           144838 non-null  float64\n",
      " 59  2018-09           144838 non-null  float64\n",
      " 60  2019-09           144838 non-null  float64\n",
      " 61  2014-10           144838 non-null  float64\n",
      " 62  2015-10           144838 non-null  float64\n",
      " 63  2016-10           144838 non-null  float64\n",
      " 64  2017-10           144838 non-null  float64\n",
      " 65  2018-10           144838 non-null  float64\n",
      " 66  2019-10           144838 non-null  float64\n",
      " 67  2014-11           144838 non-null  float64\n",
      " 68  2015-11           144838 non-null  float64\n",
      " 69  2016-11           144838 non-null  float64\n",
      " 70  2017-11           144838 non-null  float64\n",
      " 71  2018-11           144838 non-null  float64\n",
      " 72  2019-11           144838 non-null  float64\n",
      " 73  2014-12           144838 non-null  float64\n",
      " 74  2015-12           144838 non-null  float64\n",
      " 75  2016-12           144838 non-null  float64\n",
      " 76  2017-12           144838 non-null  float64\n",
      " 77  2018-12           144838 non-null  float64\n",
      " 78  2019-12           144838 non-null  float64\n",
      " 79  engagement        242957 non-null  float64\n",
      " 80  status            242957 non-null  object \n",
      "dtypes: float64(76), object(5)\n",
      "memory usage: 152.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gear_score</th>\n",
       "      <th>2015-01</th>\n",
       "      <th>2016-01</th>\n",
       "      <th>2017-01</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2020-01</th>\n",
       "      <th>2015-02</th>\n",
       "      <th>2016-02</th>\n",
       "      <th>2017-02</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2018-11</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2014-12</th>\n",
       "      <th>2015-12</th>\n",
       "      <th>2016-12</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-12</th>\n",
       "      <th>2019-12</th>\n",
       "      <th>engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>242940.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.00000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>144838.000000</td>\n",
       "      <td>242957.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>422.762538</td>\n",
       "      <td>6.974475</td>\n",
       "      <td>5.342969</td>\n",
       "      <td>6.785947</td>\n",
       "      <td>6.525649</td>\n",
       "      <td>8.827145</td>\n",
       "      <td>9.146909</td>\n",
       "      <td>5.315746</td>\n",
       "      <td>4.392204</td>\n",
       "      <td>5.343812</td>\n",
       "      <td>...</td>\n",
       "      <td>5.628488</td>\n",
       "      <td>7.517585</td>\n",
       "      <td>7.487890</td>\n",
       "      <td>9.990804</td>\n",
       "      <td>6.899764</td>\n",
       "      <td>6.001954</td>\n",
       "      <td>6.50640</td>\n",
       "      <td>8.552037</td>\n",
       "      <td>6.980226</td>\n",
       "      <td>0.380545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52.731695</td>\n",
       "      <td>13.800024</td>\n",
       "      <td>13.759982</td>\n",
       "      <td>13.816179</td>\n",
       "      <td>13.521400</td>\n",
       "      <td>14.406265</td>\n",
       "      <td>16.154893</td>\n",
       "      <td>11.170896</td>\n",
       "      <td>11.634628</td>\n",
       "      <td>12.633190</td>\n",
       "      <td>...</td>\n",
       "      <td>12.913664</td>\n",
       "      <td>13.403987</td>\n",
       "      <td>15.692877</td>\n",
       "      <td>17.119356</td>\n",
       "      <td>14.228129</td>\n",
       "      <td>13.017865</td>\n",
       "      <td>14.19111</td>\n",
       "      <td>13.318722</td>\n",
       "      <td>14.499861</td>\n",
       "      <td>0.629304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>437.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>462.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>366.00000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gear_score        2015-01        2016-01        2017-01  \\\n",
       "count  242940.000000  144838.000000  144838.000000  144838.000000   \n",
       "mean      422.762538       6.974475       5.342969       6.785947   \n",
       "std        52.731695      13.800024      13.759982      13.816179   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%       400.000000       1.000000       0.000000       1.000000   \n",
       "50%       437.000000       2.000000       2.000000       2.000000   \n",
       "75%       462.000000       7.000000       5.000000       6.000000   \n",
       "max       486.000000     413.000000     402.000000     426.000000   \n",
       "\n",
       "             2018-01        2019-01        2020-01        2015-02  \\\n",
       "count  144838.000000  144838.000000  144838.000000  144838.000000   \n",
       "mean        6.525649       8.827145       9.146909       5.315746   \n",
       "std        13.521400      14.406265      16.154893      11.170896   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       2.000000       1.000000       0.000000   \n",
       "50%         3.000000       4.000000       4.000000       2.000000   \n",
       "75%         6.000000      10.000000      11.000000       6.000000   \n",
       "max       414.000000     368.000000     326.000000     336.000000   \n",
       "\n",
       "             2016-02        2017-02  ...        2017-11        2018-11  \\\n",
       "count  144838.000000  144838.000000  ...  144838.000000  144838.000000   \n",
       "mean        4.392204       5.343812  ...       5.628488       7.517585   \n",
       "std        11.634628      12.633190  ...      12.913664      13.403987   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       1.000000       1.000000   \n",
       "50%         1.000000       1.000000  ...       2.000000       4.000000   \n",
       "75%         4.000000       5.000000  ...       5.000000       8.000000   \n",
       "max       393.000000     315.000000  ...     374.000000     466.000000   \n",
       "\n",
       "             2019-11        2014-12        2015-12        2016-12  \\\n",
       "count  144838.000000  144838.000000  144838.000000  144838.000000   \n",
       "mean        7.487890       9.990804       6.899764       6.001954   \n",
       "std        15.692877      17.119356      14.228129      13.017865   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       1.000000       1.000000       0.000000   \n",
       "50%         3.000000       4.000000       3.000000       2.000000   \n",
       "75%         7.000000      11.000000       6.000000       6.000000   \n",
       "max       367.000000     399.000000     490.000000     496.000000   \n",
       "\n",
       "            2017-12        2018-12        2019-12     engagement  \n",
       "count  144838.00000  144838.000000  144838.000000  242957.000000  \n",
       "mean        6.50640       8.552037       6.980226       0.380545  \n",
       "std        14.19111      13.318722      14.499861       0.629304  \n",
       "min         0.00000       0.000000       0.000000       0.000000  \n",
       "25%         1.00000       2.000000       1.000000       0.000000  \n",
       "50%         2.00000       4.000000       3.000000       0.000000  \n",
       "75%         7.00000      10.000000       6.000000       1.000000  \n",
       "max       366.00000     328.000000     486.000000       2.000000  \n",
       "\n",
       "[8 rows x 76 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['player', 'realm', 'last_login', 'time_since_login', 'status'], axis = 1)\n",
    "df.to_csv(os.path.join(cn.clean_dir,'stripped_final_time_stats.csv'))\n",
    "df.describe().to_csv(os.path.join(cn.clean_dir, 'eda', 'time_series_descriptive_stats.csv'))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose Data so the x = time and y = player achievements/month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = [float(str(i).replace('-','')) for i in df.index.values] \n",
    "\n",
    "df_m = df.groupby('engagement').mean()\n",
    "display(HTML(df_m.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mean achievements per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dft = df_m.T.reset_index()\n",
    "dft = dft.iloc[1:][:]\n",
    "dft.columns.values[0] = 'dates'\n",
    "dft.dates = pd.to_datetime(dft.dates)\n",
    "dft = dft.sort_values('dates')\n",
    "dft = dft.set_index('dates')\n",
    "dft.columns = ['active','risk','lapsed']\n",
    "#dft = dft.astype(float).diff(baseline)\n",
    "dft.to_csv(os.path.join(cn.clean_dir, 'eda', 'time_series_plot_data.csv'))\n",
    "display(HTML(dft.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot mean achievements per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "a = ax.plot_date(sorted(dft.index), dft.active, label = 'active',   fmt = '-4', \n",
    "                 color = 'darkcyan', alpha = 0.5, linewidth=4,marker = 'o', \n",
    "                 markersize=10)\n",
    "a = ax.plot_date(sorted(dft.index), dft.risk, label = 'at-risk',   fmt = '-4', \n",
    "                 color = 'dodgerblue', alpha = 0.5, linewidth=4,marker = 'o', \n",
    "                 markersize=10)\n",
    "a = ax.plot_date(sorted(dft.index), dft.lapsed, label = 'lapsed',   fmt = '-4', \n",
    "                 color = 'mediumpurple', alpha = 0.5, linewidth=4,marker = 'o', \n",
    "                 markersize=10)\n",
    "\n",
    "\n",
    "a = ax.set_xlabel('\\nTime (years)', fontsize = 28, color = 'wheat')\n",
    "a = ax.set_ylabel('Achievements/Month \\n', fontsize = 28, color = 'wheat')\n",
    "a = ax.tick_params(labelsize = 24, labelcolor = 'wheat')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, fontsize = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df.engagement.hist(bins = 20, figsize = (5,5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "y = df.engagement\n",
    "X = df.drop('engagement', axis = 1)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 10, test_size = 0.25, random_state = 17)\n",
    "for train_index, test_index in split.split(df, df.engagement):\n",
    "    strat_train = df.iloc[train_index][:]\n",
    "    strat_test = df.iloc[test_index][:]\n",
    "    whole_training_set = df_original.iloc[train_index][:]\n",
    "    whole_test_set = df_original.iloc[test_index][:]\n",
    "    whole_training_set.to_csv(os.path.join(cn.clean_dir, 'whole_training_set.csv'), index = False)\n",
    "    whole_test_set.to_csv(os.path.join(cn.clean_dir, 'whole_test_set.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = strat_train.engagement.hist(bins = 20, figsize = (5,5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "split = ShuffleSplit(n_splits = 10, test_size = 0.25, random_state = 17)\n",
    "for train_index, test_index in split.split(df, df.engagement):\n",
    "    shuff_train = df.iloc[train_index][:]\n",
    "    shuff_test = df.iloc[test_index][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = shuff_train.engagement.hist(bins = 24, figsize = (5,5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ShuffleSplit vs Stratified Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame()\n",
    "t['overall'] = df.engagement.value_counts()/len(df.index.values)\n",
    "t['stratified'] = strat_test.engagement.value_counts()/len(strat_test.index.values)\n",
    "t['shuffled'] = shuff_test.engagement.value_counts()/len(shuff_test.index.values)\n",
    "t['shuff_p_err'] = 100 * (t.overall - t.shuffled)/ t.overall\n",
    "t['strat_p_err'] = 100 * (t.overall - t.stratified)/ t.overall\n",
    "t = t.sort_index()\n",
    "display(HTML(t.to_html()))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (12,8), dpi = 100)\n",
    "ax[0].plot(t.index.values, t['overall'], alpha = 0.5, label = 'overall', color = 'black', lw = 2)\n",
    "ax[0].plot(t.index.values, t['stratified'], alpha = 0.5, label = 'stratified', color = 'magenta')\n",
    "ax[0].plot(t.index.values, t['shuffled'], alpha = 0.5, label = 'shuffled', color = 'darkorange')\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "sampling_plot0 = ax[0].legend(handles, labels)\n",
    "ax[0].set_title ('% of testing instances')\n",
    "    \n",
    "ax[1].plot(t.index.values, t['strat_p_err'], alpha = 0.5, label = 'stratified', color = 'magenta')\n",
    "ax[1].plot(t.index.values, t['shuff_p_err'], alpha = 0.5, label = 'shuffled', color = 'darkorange')\n",
    "handles, labels = ax[1].get_legend_handles_labels()\n",
    "sampling_plot1 = ax[1].legend(handles, labels)\n",
    "ax[1].axhline(0, ls = ':', color = 'silver')\n",
    "ax[1].set_title ('% err from overall')\n",
    "    \n",
    "    ## Remove Category for Stratification from the dataset\n",
    "#for set_ in (strat_train_set, strat_test_set):\n",
    " #   set_.drop(label, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified is the clear winner with the lowest error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train.to_csv(os.path.join(cn.clean_dir,'time_stratified_train.csv'), index = False)\n",
    "strat_test.to_csv(os.path.join(cn.clean_dir,'time_stratified_test.csv'), index = False)\n",
    "strat_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No weights, no gear score\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "           0      0.827     0.984     0.899     26915\n",
    "           1      0.877     0.522     0.654     10146\n",
    "           2      0.926     0.317     0.472      1508\n",
    "\n",
    "    accuracy                          0.836     38569\n",
    "   macro avg      0.877     0.608     0.675     38569\n",
    "weighted avg      0.844     0.836     0.818     38569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No weights, with gear score\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0      0.862     0.973     0.914     27046\n",
    "           1      0.839     0.627     0.717     10146\n",
    "           2      0.961     0.362     0.526      1508\n",
    "\n",
    "    accuracy                          0.859     38700\n",
    "   macro avg      0.887     0.654     0.719     38700\n",
    "weighted avg      0.859     0.859     0.847     38700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6/240 weighted 1,7,5,15\n",
    "            ind precision recall f1-score support\n",
    "0             0     0.742  0.989    0.848   23642\n",
    "1             1     0.707  0.113    0.195    3421\n",
    "2             2     0.822  0.182    0.298    5114\n",
    "3             3     0.823  0.144    0.246    1254\n",
    "4      accuracy                     0.744   33431\n",
    "5     macro_avg     0.773  0.357    0.397   33431\n",
    "6  weighted_avg     0.753  0.744    0.674   33431\n",
    "Plotting the confusion matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "y_train = strat_train.engagement\n",
    "X_train = strat_train.drop('engagement',axis = 1)\n",
    "y_test = strat_test.engagement\n",
    "X_test = strat_test.drop('engagement',axis = 1)\n",
    "\n",
    "\n",
    "fig1, axes = plt.subplots( figsize=(10,10), dpi=100)\n",
    "a = sns.distplot(df_original.engagement, color=\"darkcyan\",  axlabel='status')\n",
    "a.set_xticklabels(df_original.status, rotation = 45)\n",
    "fig1.savefig(os.path.join(cn.clean_dir, 'pickles',\n",
    "            'histplot_time_balanced.png'), dpi=180)\n",
    "\n",
    "\n",
    "print(\"Start random forest...\")\n",
    "\n",
    "#class_weight = dict({0:1, 1:7, 2:5, 3:15})\n",
    "#selected = RandomForestClassifier(bootstrap=True,\n",
    "#            class_weight=class_weight, n_estimators=300,\n",
    "#            oob_score=True,random_state=17)\n",
    "\n",
    "selected = RandomForestClassifier(n_estimators = 300,n_jobs = -1,\n",
    "                           oob_score = True,bootstrap = True,random_state = 17)\n",
    "selected.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Important Features...\")\n",
    "importances = selected.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "important_features = X_train.columns.values[indices]\n",
    "for i, v in enumerate(important_features[:25]):\n",
    "    print(i,v)\n",
    "\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "predictions = selected.predict(X_test)\n",
    "df_pred = pd.DataFrame(X_test)\n",
    "df_pred['prediction'] = predictions\n",
    "df_pred['actual'] = y_test\n",
    "\n",
    "\n",
    "print('Getting accuracy score...')\n",
    "print(selected.score(X_train,y_train))\n",
    "\n",
    "\n",
    "print('Oob score...')\n",
    "print(selected.oob_score_)\n",
    "\n",
    "print (\"Making confusion matrix...\")\n",
    "# Print the confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test,predictions)\n",
    "print(cnf_matrix)\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "met = metrics.classification_report(y_test, predictions, digits=3)\n",
    "folder = os.path.join(cn.clean_dir, 'pickles')\n",
    "f_name = 'metrics_time_balanced_metrics.csv'\n",
    "print(met)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Plotting the confusion matrix...\")\n",
    "fig2, ax = plt.subplots(figsize = (8,8))\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'viridis', fmt = 'g', annot_kws={\"size\":16})\n",
    "ax.set_xlabel (\"Predicted Value\", fontsize = 18)\n",
    "ax.set_ylabel (\"Actual Value\", fontsize = 18)\n",
    "ax.tick_params (labelsize = 14)\n",
    "plt.tight_layout()\n",
    "fig2.savefig(os.path.join(cn.clean_dir, 'pickles','cnfmatrix_time_balanced.png'), dpi=180)\n",
    "\n",
    "# save the model to disk\n",
    "pickle_name = 'rf_time_balanced_model.sav'\n",
    "os.chdir(os.path.join(cn.clean_dir, 'pickles'))\n",
    "with open(pickle_name, 'wb') as file:\n",
    "    pickle.dump(selected, file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ins_env",
   "language": "python",
   "name": "ins_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
